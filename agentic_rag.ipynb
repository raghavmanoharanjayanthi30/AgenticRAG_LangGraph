{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41de1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "#https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d671c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents from directory\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"pinnacle_capstone_data\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7cd3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb381c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with embedding models\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import os, yaml\n",
    "\n",
    "with open('chatgpt_api_credentials.yml') as f:\n",
    "    credentials = yaml.safe_load(f)\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=credentials['openai_key']\n",
    "\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')\n",
    "\n",
    "llama_embed_model = OllamaEmbeddings(\n",
    "    model=\"llama3.2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5c2856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d287dca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bea9a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma/\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Two vecto stores for two embedding models -> different collections to avoid dimensionality error \n",
    "# Open ai and llama embeddings have different lengths\n",
    "vector_store1 = Chroma(collection_name=\"openai_collection_1\", embedding_function=openai_embed_model,\n",
    "                      persist_directory=\"./chroma_db3\")\n",
    "\n",
    "#vectordb = Chroma.from_documents(documents=splits, embedding=openai_embed_model)\n",
    "#vectordb = Chroma.from_documents(documents=splits, embedding=llama_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4c066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store2 = Chroma(\n",
    "    collection_name=\"llama_collection_1\", \n",
    "    embedding_function=llama_embed_model,\n",
    "    persist_directory=\"./chroma_db4\"  # Specify a directory to store the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8908edc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x114e409d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12bcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f034367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add documents to both vector stores\n",
    "document_ids_1 = vector_store1.add_documents(documents=all_splits[:])\n",
    "document_ids_2 = vector_store2.add_documents(documents=all_splits[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1846ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store1.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ce6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"what is attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df2ca084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c53bf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/81/7z5hxt0d3cbd95svhrc31swh0000gn/T/ipykernel_19882/868067471.py:39: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Output parser will split the LLM result into a list of queries\n",
    "class LineList(BaseModel):\n",
    "    # \"lines\" is the key (attribute name) of the parsed output\n",
    "    lines: List[str] = Field(description=\"Lines of text\")\n",
    "\n",
    "\n",
    "class LineListOutputParser(PydanticOutputParser):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return LineList(lines=lines)\n",
    "\n",
    "\n",
    "#output_parser = LineListOutputParser()\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate two \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# Run\n",
    "multi_query_retriever = MultiQueryRetriever(\n",
    "    retriever=vector_store1.as_retriever(), llm_chain=llm_chain #parser_key=\"lines\"\n",
    ")  # \"lines\" is the key (attribute name) of the parsed output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412fc662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results\n",
    "unique_docs = multi_query_retriever.invoke(input=\"What is attention\")\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f05f469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='9366f1f0-3ce5-401a-944b-ec7d02607ab4', metadata={'author': '', 'creationdate': '2024-04-10T21:11:43+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'page': 12, 'page_label': '13', 'producer': 'pdfTeX-1.40.25', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'source': 'pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': '/False'}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc3f172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vector_store2.as_retriever(), llm=llm\n",
    ")\n",
    "unique_docs = retriever_from_llm.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "266aeed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfb32a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the parent documents\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"full_documents\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "# This text splitter is used to create the child documents\n",
    "# It should create documents smaller than the parent\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "store = InMemoryStore()\n",
    "p_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d12814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06534050",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = p_retriever.invoke(\"what is attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92917b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13db8759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2 Attention\n",
      "An attention function can be described as mapping a query and a set of key-value pairs to an output,\n",
      "where the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n",
      "3\n",
      "\n",
      "////////\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\n",
      "\n",
      "////////\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(retrieved_docs)):\n",
    "    print(retrieved_docs[i].page_content)\n",
    "    print()\n",
    "    print('////////')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "467097f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/opt/homebrew/lib/python3.11/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "030eba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    #retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    retrieved_docs = multi_query_retriever.invoke(input=state['question'])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93f9535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f4282d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention is a mechanism in machine learning models that allows them to focus on specific parts of input data during processing. It helps the model to prioritize certain information and make more informed decisions based on the highlighted features. In the context provided, attention is visualized as heads attending to distant dependencies in the input data, such as completing phrases or identifying key words.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is attention?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac47392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR AGENTIC RAG\n",
    "import os, yaml\n",
    "with open('tavily_api_credentials.yml') as f:\n",
    "    credentials = yaml.safe_load(f)\n",
    "os.environ['TAVILY_API_KEY']=credentials['TAVILY_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa214d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tv_search = TavilySearchResults(max_results=3, search_depth='advanced',max_tokens=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989f01b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f90f6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "\n",
    "# 1.QUERY RETRIEVAL GRADER\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Data model for LLM output format\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "# LLM for grading\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "# Prompt template for grading\n",
    "SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n",
    "                Follow these instructions for grading:\n",
    "                  - If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n",
    "                  - Your grade should be either 'yes' or 'no' to indicate whether the document is relevant to the question or not.\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        (\"human\", \"\"\"Retrieved document:\n",
    "                     {document}\n",
    "                     User question:\n",
    "                     {question}\n",
    "                  \"\"\"),\n",
    "    ]\n",
    ")\n",
    "# Build grader chain\n",
    "doc_grader = (grade_prompt\n",
    "                  |\n",
    "              structured_llm_grader)\n",
    "\n",
    "# 2.QUESTION REWRITER\n",
    "\n",
    "SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n",
    "                 - Convert the following input question to a better version that is optimized for web search.\n",
    "                 - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n",
    "             \"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", SYS_PROMPT),\n",
    "        (\"human\", \"\"\"Here is the initial question:\n",
    "                     {question}\n",
    "                     Formulate an improved question.\n",
    "                  \"\"\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "chatgpt = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "# Create rephraser chain\n",
    "question_rewriter = (re_write_prompt\n",
    "                        |\n",
    "                       chatgpt\n",
    "                        |\n",
    "                     StrOutputParser())\n",
    "\n",
    "\n",
    "\n",
    "# QA RAG CHAIN\n",
    "prompt1 = \"\"\"You are an assistant for question-answering tasks.\n",
    "            Use the following pieces of retrieved context to answer the question.\n",
    "            If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
    "            Do not make up the answer unless it is there in the provided context.\n",
    "            Give a detailed answer and to the point answer with regard to the question.\n",
    "            Question:\n",
    "            {question}\n",
    "            Context:\n",
    "            {context}\n",
    "            Answer:\n",
    "         \"\"\"\n",
    "prompt_template1 = ChatPromptTemplate.from_template(prompt1)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def format_history(history):\n",
    "    return \"\\n\".join(f\"User: {turn['question']}\\nAssistant: {turn['answer']}\" for turn in history)\n",
    "\n",
    "\n",
    "# QA RAG CHAIN\n",
    "prompt2 = \"\"\"You are an assistant for question-answering tasks.\n",
    "            Use the following pieces of retrieved context and conversation history to answer the question.\n",
    "            If no context is present or if you don't know the answer, just say that you don't know the answer.\n",
    "            Do not make up the answer unless it is there in the provided context.\n",
    "            Give a detailed answer and to the point answer with regard to the question.\n",
    "            Conversation History:\n",
    "            {history}\n",
    "            Question:\n",
    "            {question}\n",
    "            Context:\n",
    "            {context}\n",
    "            Answer:\n",
    "         \"\"\"\n",
    "prompt_template2 = ChatPromptTemplate.from_template(prompt2)\n",
    "\n",
    "    \n",
    "# create QA RAG chain with conversation history\n",
    "# create QA RAG chain\n",
    "qa_rag_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context')\n",
    "                        |\n",
    "                    RunnableLambda(format_docs)),\n",
    "        \"question\": itemgetter('question')\n",
    "    }\n",
    "      |\n",
    "    prompt_template1\n",
    "      |\n",
    "    chatgpt\n",
    "      |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "qa_rag_chain_with_history = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context') | RunnableLambda(format_docs)),\n",
    "        \"question\": itemgetter('question'),\n",
    "        \"history\": itemgetter('history') | RunnableLambda(format_history)\n",
    "    }\n",
    "    | prompt_template2\n",
    "    | chatgpt\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d837074d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x114f008d0>, search_type='mmr', search_kwargs={})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "71747e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING THE RAG AGENT\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM response generation\n",
    "        web_search_needed: flag of whether to add web search - yes or no\n",
    "        documents: list of context documents\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    generation: str\n",
    "    web_search_needed: str\n",
    "    documents: List[str]\n",
    "    history: List[dict]\n",
    "\n",
    "def retrieve_v2(state:GraphState):\n",
    "    question = state['question']\n",
    "    retrieved_docs = p_retriever.invoke(question)\n",
    "    return {\"documents\": retrieved_docs, \"question\": question}\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "\n",
    "def grade_documents(state:GraphState):\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    filtered_docs = []\n",
    "    web_search_needed = 'No'\n",
    "    if documents:\n",
    "        for d in documents:\n",
    "            score = doc_grader.invoke({'question':question, 'document': d.page_content})\n",
    "            grade = score.binary_score\n",
    "            if grade == 'yes':\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                web_search_needed = 'Yes'\n",
    "    else:\n",
    "        web_search_needed = 'Yes'\n",
    "        \n",
    "    return {\"documents\": filtered_docs, \"question\": question, \n",
    "            \"web_search_needed\": web_search_needed}\n",
    "        \n",
    "def rewrite_query(state:GraphState):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "def web_search(state:GraphState):\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    docs = tv_search.invoke(question)\n",
    "    web_results = \"\\n\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate_answer(state:GraphState):\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \n",
    "            \"generation\": generation}\n",
    "\n",
    "def generate_answer_v2(state:GraphState):\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    history = state['history']\n",
    "\n",
    "    response = qa_rag_chain_with_history.invoke({\"question\": question, \"context\": documents, \"history\": history})\n",
    "    history.append({\"question\": question, \"answer\": response})\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": response, \"history\": history}\n",
    "\n",
    "def should_generate(state:GraphState):\n",
    "    web_search_needed = state['web_search_needed']\n",
    "    \n",
    "    if web_search_needed =='Yes':\n",
    "        return 'web_search'\n",
    "        #return 'rewrite_query'\n",
    "    return 'generate_answer_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "db93b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "agentic_rag = StateGraph(GraphState)\n",
    "agentic_rag.add_node(\"retrieve_v2\", retrieve_v2)\n",
    "agentic_rag.add_node(\"grade_documents\", grade_documents)\n",
    "#agentic_rag.add_node(\"rewrite_query\", rewrite_query)\n",
    "agentic_rag.add_node(\"web_search\", web_search)\n",
    "agentic_rag.add_node(\"generate_answer_v2\", generate_answer_v2)\n",
    "\n",
    "agentic_rag.set_entry_point(\"retrieve_v2\")\n",
    "agentic_rag.add_edge(\"retrieve_v2\", \"grade_documents\")\n",
    "\n",
    "agentic_rag.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    should_generate,\n",
    "    {\"web_search\": \"web_search\", \"generate_answer_v2\": \"generate_answer_v2\"},\n",
    ")\n",
    "#agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n",
    "agentic_rag.add_edge(\"web_search\", \"generate_answer_v2\")\n",
    "agentic_rag.add_edge(\"generate_answer_v2\", END)\n",
    "agentic_rag_compiled = agentic_rag.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "86f7c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANIAAAITCAIAAAD90NUtAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcFMffx2fvjrvj7qhHOXpXqtIsESMqGrtGQcUao9i7oGLXRGOP/myxJbGLJZZYosYS0USjKEiRKr13rsDBteeP9bkQc3CgC3O3zPvFH7c7u7OfWz43Mzs78x1MoVAABKJ9ocAWgOiIINshIIBsh4AAsh0CAsh2CAgg2yEgQIMtAAJlefVCvrSWL5OI5fViOWw56tGhYxQaxtansfWpJlZMOhODrehTwTpOv11WQu27BEFWosjOjdVQr2DrU43N6Q31WmA7OoPCr5TW8qUivlRQJdUz1nH0ZHfy02PpUWFL+0g6hO3S44TPbpRbOrGsnXUdPNkMlnY3LQoy6rISReWF9SZWjF4jTCha+G1Ibrs6oez3MyV0XUqv4Sb6XLK1KOL+qP7zRnm/sWbuPfVha2kdZLZdfnrdnZPFY+ZbGVvQYWtpQ57frhTXyvqGmMIW0gpIa7vywoan18q+nGcFW0h7kPBnTXG2eOAkc9hCWgo5bZfxRpjwtGb0/A7hOZykv/jpcQJt+ZlpYXNUHdVlkue3KjqU5wAAHr307d3ZT6+VwxbSIkhou0cXSydG2sFWAQHvvoY0HUraayFsIeohm+2e3ayw7czSxj4FQvDpb/jHpVLYKtRDqv9PfZ084c8avwFGsIVAg6FL8QoweHW/CrYQNZDKdrF/VPcNMYOtAjKfDefmptYCzX5QJJXtEv+ssems255XfPfu3fDhwz/ixJUrV964caMNFAG8zMtMELVR5oRAHtsVZ4sNTXV0Oe36mjI5ObmdT2wJDp7szESNfrAgj+3y0uo6+7XVO6Li4uLIyMiBAwf26tUrJCTkypUrAIAjR45s3LixuLjY39//3LlzAIA7d+5MmjTp888/DwoKWrp0aX5+Pn76xYsXBw4c+Pjx44EDB+7du9ff37+wsHDTpk19+/ZtC7VOXpyaMklb5EwYCrJw68fCd2+EbZT5nDlzpk+fnpiYmJeXd+nSpW7duj179qyurm7nzp1Dhw6tqqoSi8WJiYl+fn4HDx7MyspKTEycPXt2aGgofvqVK1cCAgLmzJnz9OnT/Pz8kpISPz+/qKio6urqNhJ8dPW7OpGsjTL/dMjzdlxUI2UbtFUNm5GRMX78eA8PDwBASEiIq6urhYUFk8lkMBgYhhkaGgIA7OzsTp8+7eLiQqPRAAATJ05ctmxZZWWlsbExhmFisXjixIkBAQEAgPr6egAAi8UyMDBoI8FsfZqoRspkaejLaBLZji9j6bfV1+nTp8+JEycEAkFAQICPj4+np+d/j+FwOAUFBQcOHMjLyxOLxRKJBADA5/ONjY3xA7y8vNpI3n9h61Nr+VKupo6BII/tdOgUKq2tht2uWrXK2dn59u3bZ8+eZbPZISEhc+fOxUs1Jffu3Vu9evWMGTOWL1/O4XDi4uIiIyMbH8DhcNpI3n+h61LlGjyAlTy2o9ExYbW0jQbc0mi0CRMmTJgwoaKi4tatW4cOHTIyMpo8eXLjY65everv7z937lx8UywWt4WSFlJT1sDW19yxx+R5ksWrlbbIWSgU/vbbb1KpFADA5XKnTp3q5eWVkZHxwWENDQ14Iw/nzp07+BNbU9m26difNm1yfDrksZ2pDVNc1yb/SAzDtm/fvnnz5tTU1IKCgjt37iQnJ/v5+QEA9PT0ysvLY2Nji4qKPD09nz9/npiYWFRUtHXrVhMTEwDA27dv/1vsMRgMBoPx+vXr1NRU3M3EopADYx5dk2daaO4PorVY2DPj/qh29Se+/cRmsw8cOHDgwIHZs2c3NDRYWlrOmTNnxIgRAIDBgwffvHlz7ty506ZNmz59en5+/ty5c9ls9pgxY8LCwsrKyjZv3kylqvj3T5s27eTJk0+ePLl27Zqenh6xgjMThEzNni9CqmGehyLezd7m2HYPFtrC/XMl1s4s1+4Eu5lANPo30Vq8AgzyUutgq4BPLV9m78GGraI5yFPJAgA8exnc/qnQ3qPJMZ7ffvvtgwcPVCbJZDKVtSEAYNOmTYGBgcTJ/BfNvB9rRtLFixfNzFSPtXnzuNrInM5ka3SBQqpKFq9frJx13bqrfjlbVVVVV6e6OKyvr2cwGCqTjI2NmUwmoTL/obCwsKmkZiSZm5s35UitaGmQzXa1AvnDqJLhMy1gC4FDfHSNXAG8A9vqnRtRaHRR/BGw9CheAQY3jjZZhJCYrCRRblqt5nuOhLYDANi5sywddR9e0IIpBQRSVSyJ/qVseJh2FPNkq2SVpMcK89Nr+43rEGPcCzPF0b+Ujo+wxTS6RfcPJCztcFx8OMY8+tWDBZr8RpwQUl4Int0qD12uNZ4jc2mHk59e98el0s7+et2+MIathXhyU2v/+rXczo392XAubC2tg+S2w19QvrhbGfuoqtsXxjadWWY2qrsktAixSJ6ZKCzKFAtrpAEjuCZW2veNyG87HGmDIv5JTXqcoJYvde2mDwBg6VH1jHXkci34+jQdTFQjE/GltQJZTbmkLE/s4MVx9dO3cmmr3sS2pqPYTomoRlbwrk5QKakVyAAAwhqCB4AkJiba29sTO6JTl0NVyBUsPRpLn2pqyeQ5aF/x9gEdznZtzZQpU1atWuXu7g5biEZD2idZhCaDbIeAALIdwdja2mJa1IEGCWQ7gsnNzUXNZbUg2xFMe85K1F6Q7QhGKNTomDcaArIdwXC5XNS2UwuyHcFUVFSgtp1akO0Ixt7entJhQye3GHSDCCY7O1tO+rFWnwyyHQICyHYEo6+vjx4p1IJsRzB8Ph89UqgF2Y5gDA0NUWmnFmQ7gsHDEcNWoekg2yEggGxHMJaWlqjfTi3oBhFMYWEh6rdTC7IdAgLIdgRja2vbVCwmhBJkO4LJzc2VyWSwVWg6yHYICCDbEYy9vT2qZNWCbEcw2dnZqJJVC7IdAgLIdgSDJiy2BGQ7gkETFlsCsh0CAsh2BIPmybYEZDuCQfNkWwKyHcGgESgtAd0ggkEjUFoCsh0CAsh2BGNsbIz67dSCbEcwlZWVqN9OLch2BGNnZ4eGAqgF2Y5gcnJy0FAAtSDbEQwKvdMS0A0iGBR6pyUg2xGMmZkZKu3UgpZDIYZBgwbR6XQMwyorKzkcjo6ODoZhDAbj0qVLsKVpIjTYAkiCnp5ednY2/lksFgMAqFTqwoULYevSUFB1QAz9+vX7oJfY2tp67Nix8BRpNMh2xDB27FhbW1vlJoVCGT16NIOh9WvStRHIdsRgZmYWGBioLPBsbW3HjRsHW5TmgmxHGBMmTMALPCqVOmrUKDqdDluR5oJsRximpqZ9+/bFMMzGxgYVdc2jrU+yMomiorhBUCXVqA6gAO/g108KP//887wUCQAS2HL+gc6kmlrRdTma8rJYK/vtYn6vSn0loNIwI3NGQz16JaAehi4lN1lk5aQ7YKKZDgN+Fad9tvvrRqW4Tt5tkAlsIdpHWV79s5slwQutmWzIzoNv/Fbx953KhnoF8tzHYWrDGDDZ6tz2HNhCtMp2tQJ5bkqt30AubCFaDEuP6trd8E10NVwZ2mS7qpJ6NF780+EY0oqzxXA1aJPthDVSYx4TtgqtR59LbxBDbtBrk+3kMkWDGA3c/VTkcoVYBPk2apPtEKQB2Q4BAWQ7BASQ7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAANkOAQFkOwQEtHVQezuzYeMKoVCwe9cPsIUAAEB2dubR4/vfvk0AALi5ec6cscDR0Rm2qNaBSrv3ZGW9C504vKnU4cPHhARPbF9FqikvL1u8dKZAwI9csXFFxPrKivIVkQu0Ljw8Ku3ek5aW3ExqN/+e7ailOe7euykW1323Za8eRw8AYGFhNT1sfGJiXM+evWFLawUkL+02blq56ZvIn08cHjKs97NnTwAAaekpK1YuGDU6aNiIPuvWRxQXFwEATpw8sm3HxpKS4n5B/pd/OZeV9a5fkP9ff0VPmz527rypeCUbHjEXz7O6uuq7bevHTxg2eGjAvAXTYuNiAAAvY573C/LHKz6ct8mJ/YL8X8Y8b+qizdBMbiNGBB8/eh73HADAzIwHAODza9rk9rUZJLedjo5OZlZGWnrKtu/2ubt7lZQULwufjVEoe3Yf2b3rMF9QE758bkNDQ+j4r8aMCTUzM7925f6I4cE6OjoAgJOnjo4fN2V5xPrGGcrl8pWRC5OS4leu2HjkhzOund0jVy3KzMzw9elmaGj05Okj5ZHR0Q8MDY18fbo1ddFmZDeTm76evo2NnXL/3y/+xDDM3aML0XeubSG57RQAFBbmR67c1LWrr4GB4a83LmMYtnbNFkdHZ9fO7qsjvy0qKngc/YDJZDLoDAzDDAwMGQwGwDAAgLe3/5DBIz9orce8+jstPSUifK2vTzc7O4cF8yPMzS2uXI2iUqmBfYIaG+XJk4f9+g6kUqlNXbQZ2c3k1viw4uKifft3DB822trKhtDb1uaQ3HYAABsbOwN9A/xzcnKia2cPZQ1lbs6zsLDKyEhVeaK7u9d/dyYnJ+ro6Hh39cM3KRRKFy8fPIe+gQMLCvKyst7htWphUUFQ/8GtvaiSpnJTkpeXs3hpmItz5wXzI1p/VyBD/kcKNvuftedEImF6RuoXgz9T7pFIJBWV5WpPVFJbK5JIJIOG9FLukclkxsZcAECXLj5crsmTp48cHJyiox/wzC08PLq09qJKmsoNJzUteWXkQi9P73Vrv9PGYCvkt11j2GyOl5d3+NI1jXfq6rJalQOdTj925FzjnXjUWAqFEhg44OnTR1OnhEU/edi//6BPuWhTuQEAcnOzl6+Y3zugb/iyNVq6GAH5K9nGuLl5FhTkWVpa29ra438YhnG5rZjs7erq0dDQIJPJlDnQ6QwTEzM8tV/gwPSM1FevX+Tl5SjrxI++qMrcpFLp2vXhfr7dl0es01LPdTjbjRgeXFdXu33HxvSM1Pz83FOnj389Y1xKShIAgMPRq6goj4+Pbb53w8+3u4tz5++2rouLe1VUXHj/wZ1Zsyde//V9gGIPjy7m5rwfDu9xdHRWPos0c9HmUZnb9V8vFxbm9+8/KO7Nq9i4GPwvLw/+RP9W0bEqWR7P4vvdR44e3bdo8QwqlWpv77T52+/xR4eg/oPv3rsZvnzuxAnTBg4c1lQOVCp1+7b9PxzZu2HTCrG4jseznDIlbGzIJDwVw7DAPgMuXjozM2xBSy7aPCpzi417KZPJ1m9Y3vjIEcPHLFu6+mPvCgS0KfRO8gt+TrI44Esz2EK0m7J88at75WOXWkPU0LEqWYSG0LEqWY1i1ZoliYlxKpOGDR09Z/bidlfUfiDbQSNi2doGiepXZCwWu93ltCvIdtBoVccNyUBtOwQEkO0QEEC2Q0AA2Q4BAWQ7BASQ7RAQQLZDQADZDgEBZDsEBLTJdjoMCgP2qkVkQIEZmurAlaBN/0Uuj56fJoKtQuspy69jsiEPS9Ym2xmZ0/UMdeoEaGmKT6KmrMHeA/JQA22yHQAgMMT0/rlC2Cq0mL9vl+kb02w66cKVoU2ji3H4FdLTW7J7jjDTN9LhGOko5FqmHwpyGSgvFJdk1xma0XoMNoYtRwttBwBQyMHz3yqKs8XSBkWdULPqXJFIpMtkUjRsThfXgk7Xpbj46Nm7t2J2ZtuhlbbTZKZMmbJq1Sp3d3fYQjQaLWvbIcgBsh0CAsh2BGNvb4/HpkA0A7pBBJOdnS2Xy2Gr0HSQ7QjGysoKrSyvFmQ7gikoKECdA2pBtiMYW1tb1LZTC7pBBJObm4vadmpBtiMY1LZrCch2BIPadi0B2Q4BAWQ7grGyskKPFGpBN4hgCgoK0COFWpDtEBBAtiMYbVwlov1BtiOY5hcTQ+Ag2xGMnp4e6rdTC7IdwQgEAtRvpxZkOwQEkO0IxtTUFPXbqQXdIIIpKytD/XZqQbZDQADZjmCsra1RJasWdIMIJj8/H1WyakG2Q0AA2Y5g0ITFloBuEMGgCYstAdkOAQFkO4KxtLRE72TVgmxHMIWFheidrFqQ7QgGjUBpCch2BINGoLQEZDsEBJDtCMbW1hZVsmpBtiOY3NxcVMmqBdmOYOzs7KgaFi9bA0G2I5icnByZTLOCx2sgyHYEgwKNtQR0gwgGBRprCch2BIPadi0BLYdCDAMGDKBSqRQKpbq6msVi0Wg0CoViYmJy+vRp2NI0ERpsASSBTqeXlpbin2tqagAANBpt9OjRsHVpKKiSJQZ/f/8PHmBtbW2R7ZoC2Y4Yvv76a0tLS+UmhmF9+vQxNTWFKkpzQbYjBgcHB19fX2VD2cbGZvz48bBFaS7IdoQxdepUHo+HF3UDBgxARV0zINsRhouLi7+/v0KhsLGxGTt2LGw5Gg2EJ1lhlUwmI2eHavDIKXEv0wYEDqJjhjXlEthyiEcBMEMTAjzTrv12j38pT3vFN7NlVpeS8F/SETAw1clPq3Xw5PgPNDK3ZXx0Pu1kO5lUcXZbru8AE56dLoOFanbtpqZcEv1LcZ/RptYuzI/LoZ1sd3pLzufBFlwLFNeXPNw6lvf5lyZWzrofcW57FDxxj6s7dzNEniMZ/UMtXz+s/rhz28N2BRl1bH30Fo5s6OpRi7PrxLUf83TYLs0sBWZo/vHNT4TGYuPKrir5mMj07WG76rJ6BUl7TDo4gkrJxz0boIdKBASQ7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAANkOAQFkOwQEkO0QEEC2Q0CgA9nu6xnj/rdvO1G51dRU9wvy/+PxfaIy7FB0INshAABZWe9CJw6HrQLZroORlpYMWwLQ3BgoCQlx+/bvyMnNsrS0njtn6ZmzPzo5uixZHHn12sVTp49FLFu76/vNXwwcNnfOkqqqyh+O7H39+oVAwDc1NR/z5fgxY0KVmfxv//acnCwezzJsxvzG+VdXVx06vOfNm1c1NdWOji4zwxb4ePurVfXrjV/OnvupurrKxcU1bPq/MkxIiDv244G0tGQMw9xcPWfOXOjm6oEn3b178/yFk0VFBTyeZej4qUMGjwQArFqzBACwdcte/Jjff7/93bb1t25Es1isTd9EAgA8Pb0vXT5TXV3l7e2/auWmc+dPPHh4p6GhYUDQ4IULluPhkdPSU44fP5CaliyVSnx9us+fF87jWQAArv96+ecTh7du2bvvwM68vGx9PYPJk2cMHTLqxMkjJ08dAwD0C/KfP29ZSPDEW7evXf7lXFFRAYPB7NrFd8H8CDMzc+L+jU2iibarr69fuz7c3t7x4IETIqHw4KHdVdWVzk6dAAA6Ojpicd2Vq1ErV2y0tbUHAOzY9U1ebva6Nd8ZG3MTEuN2f7/FzJzXO6CvUChcs26Zs1Onw4dOS6SSY8f2V1SU4/nL5fKVkQuFIuHKFRu5xibXf70UuWrRDwdPOTo6N6MqPj52z96tY0MmjRg+pqAw/4fDe5RJeXk5ESvm9Q7ou3jhSgDATyd+iFg+9+cfL5mZmT+OfrBj1zczwxb4+HSLj3+9Y+c3urqsvoEDmrkQlUaLjX1pY2N35tS13NzsWXMmzVswbfy4KRfO34qNi1m+Yn6PHr17dO9VUlK8LHy2h0fXPbuPNEgafji8J3z53J9/vEin02k0mkgkPHXm+KYNO0xNzU6eOrpn79Zu/p+Fjv9KIBQ8ffro6OGzTKZufHzsrt2bw5et8fHpVlNTfeTo/zZ9G3lw/8/E/SebRBMr2WfPn/D5NUsXr3Jx7uzt7bdo4QqlYzAME4vFIcETe/YIsLSwAgDMnxe+Y8fBrl19bWzshg4Z5ezUKSbmOQDg+d9PBQL+ooUrnJxcXDu7R67cJBDw8UxiXv2dlp4SEb7W16ebnZ3DgvkR5uYWV65GNa/q3u+3jI25s2ctsrGx69kjYOzYycqk679e1tVlrYr8xsnJxcnJZc2qzVKp9O69mwCAS5fP9g7oGzp+audObmNDJoWOn1pRXqb2Dkil0qlTZtJoNEdHZ0cHZzqdPnJEMJVK9ffrYWBg+O5dGgDg1xuXMQxbu2aLo6Oza2f31ZHfFhUVPI5+oMxhYug0MzNzDMOGDB4llUrfvUtjMpkMOgPDMAMDQwaDkZX9jsFgDB40wsrS2t3Nc8O6bfPnhX/C/60VaGJpl5ubzWFz7O0d8U0vL28DA8PGB7i7eyk/6zJ1z0WdiIuLqamplsvlAgHfysoGAJCTk8lkMpWZmJqamZqa4Z+TkxN1dHS8u/rhmxQKpYuXT0ZGavOqcnKzOnVyU4ZMdHPzVCalpSd3cnGl0d7fTBaLZWNjh5sjLS152lezlUfOnrWoJXfAgmf5T25stoH+P1+fw+aIREL8W7h29tDj6OH7zc15FhZWGRmpAwcMwfc4OrrgH/T09AEAAqHgg6v4ePtjGLZoSdjQIaP8/HpY8CyNjbktkffpaKLt+PwaFpvdeI++vkHjTTabg3+QSqUrIhfIZLIF8yNsbeypVOra9e9/r7V1tQzGv2Zx6uqy3ifViiQSyaAhvZRJMplM7R2vrRVxjU3+yY2p21QSAIDFYtfWisRisUQiYTJbPaVPh05vZhMfRy4SCdMzUr8Y/Jlyv0QiqagsV24yGP+ev/Kf0ee2tvYH9v18/sLJo8f2C77f4ubmuWB+hHujn1PboYm2YzAYYrG48R4+v0blkcnJiZmZGf/bc6xLFx98T011lQXPEgDAZDDxUkGJ8P9/7mw2h06nHztyrnGq2jjXTKZu4wyFjQoP9v+XQEpEIiHX2ITJZDKZzNpakbpvDOob6tUe8wFsNsfLyzt86ZrGO5U/rRbi5OSydvVmmUyWkBD348+HVq9ZcvniHWVB23ZoYtvOysqGz68pKMzHNxMS4mpqVM/HxP9byrIwKSm+qPj9Aoe2NvZSqTQ7OxNPyszMqKyswD+7uno0NDTIZDJbW3v8j05nmJiYNa/KxtruXWa6Mhx2zKu/lUmdO7mnpiVLJO8jbAiEgtzcbFdXDwCAs3Pn+PjXyiP3H9y1/+AuvK5sbFy8Rm4Vbm6eBQV5lpbWym+BYRiXa9KCU9+TnJyYlBQPAKBSqd7eftO/nltTU/3B76eN0ETb9ezRm8FgHDi4Kzc3OyEh7ocje5u6m85Oneh0+pWrURUV5S9jnu/bv6Obf8+8/JyqqsqePXuzWKx9+3ckpyQlJMTt3bfNyMgYP8vPt7uLc+fvtq6Li3tVVFx4/8GdWbMnXv/1UvOqgoIGV1VVHvzh+8zMjOgnD+/du6lMGjVqbH29eMeub/LycjIzMzZvWcNmcwZ9MRwAEBI88WXM859PHE5JffvLlahr1y66uXoCAFxcXFNSkt69S1coFH+/+Ovly2etvUsjhgfX1dVu37ExPSM1Pz/31OnjX88Yl5KS1PxZHI5eRUV5fHxscXHR3y/+WrNu2ePoBwWF+ekZqVeuRPHMLT5oz7QRmmg7Y2PuhnXb8vJywmZNOHho97w5S9lsDp2uYqatoaHRiuUbXr58NmnKqNNnjq9csTE4eGJxceGyiDkGBobfbNpVVV25aPGM7Ts3BY+ZYGVlgxeEVCp1+7b9Do7OGzatmPZ1yOkzx6dMCRs/bkrzqrr595w/b9njx/fnzJty4eLp8PC1ymaWlaX1zu0Hi4sLw2ZNWLDoa6BQ7Nl9xNDQCAAQ2CdoyeLI+w/uLFo849r1i4sWrhgQNBgAMHJESGDggCVLZ345ZsD9+7fDwhbgPTstv0s8nsX3u49UVlYsWjxjzrwpL17+tfnb7xs/bKkkqP9gS0vr8OVzf7tzffKk6cOHjT58eO+0r0OWr5ivAIptW/e1z4Jp7RED5ezWnMCxFgamrQhGUcOvYTKYeKO4oaFh1Oj+s2YuGv3luLaUiWg1d37ODxjJtXRs9TOTJj5SCIXCyVNG+fp0nzplJoZhFy6dplAofT7vD1sXgjA00XYcDmf7tgPHju1ftGQGBaM4OXfauf1gqxrLH8eqNUsSE+NUJg0bOnrO7MVtLaDjoIm2AwC4u3nu+f5IO180YtnaBonqiB4sFlvlfsTHoaG2g0I7FKgIHE18kkWQHmQ7BASQ7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAANkOAYH2sJ2ROR2jtMdwGkQ7o8+lqx2VrZL2sB1GwSqLWz1oG6H5ZCcJjXk6H3Fie9jOtpOusBotqUg2BJUSm04sOlNTSzuPXgb5aaLspPYYpI9oN34/U9hzqPHHndte68kqwJUDBbZuHDNbXSNztOadFlMrkPHLJdFXioIXWhuafkwN297LGMf8XpX2WkBnUioKNbGpJ5fLMYzSLnMJWqIEa59pDa2Ca8HgV0kc3DndBxuzDagfnU+72g5HJgNyaXtfVC2zZs1aunSpm5sbbCHvmT59+qpVq1xcXGAL+TcKhc5HNeY+AILtEAjUXQxu3bqVkZEBW4VqDh8+/EGABHLQ0W139OhRFovl7NxciDGIzJkzZ/Hixa2aP6sVoEoWAYGOW9rdvHnzl19+ga2iRZSXly9btgy2CiLpoLZ7/PhxTU1NcHAwbCEtwsTEZO7cudu3ExZmHjqokkVAoMOVdjk5Obt27YKt4iO5e/fuvXv3YKsggI5lOz6fv3///oiICNhCPpJBgwYlJyfHxMTAFvKpoEoWAYEOVNrt2rWroKAAtgoC4PP5Bw8ehK3ik+gottu5c2f37t2trKxgCyEAfX19KyurzZs3wxby8aBKVlupqqrS1dVlMpktOFbjIH9pl5eXd/HiRdgqiMfIyOjvv//W0lKD5LaTyWTBwcHjxpEz+mx9ff3q1athq/gYSF7JSiQSGo2mgeMliSImJsbOzs7U1BS2kNZBZttlZGRgGObk5ARbCOJDSFvJpqWlrVu3riN47vjx41evXoWtonWQtrR78uSJv7+/rm6rY9drHQqFom/fvo8fP4YtpBWQ1nYITYaElWxxcTFZH12b4dGjR1o0CJmEtrt06dL69ethq2hvUlJSfvrpJ9gqWgqqZEmCRCKVXu1cAAAgAElEQVT55ZdfQkNDYQtpEWSz3W+//ebn52dmpmaVTgRcSFXJJiYmXrhwocN6LjMz89ChQ7BVtAhS2U4oFGr1uIxPxNHR8fbt28XFxbCFqIdslWwHp6CggEql8ng82ELUQB7bPX78OD8/f9KkSbCFINRDnkr20qVLjo6OsFXAZ/78+VVVVbBVqIEktlMoFJGRkZ999hlsIfDh8Xia/6KMPJUsAkcmk0mlUny9e42FJKVdVFTUuXPnYKvQCKhUqua/JSOJ7V68eEGO6TmEMGnSpJycHNgqmoMkq2dv27aNTkchkd/TvXv39PR0Ozs72EKaBLXtEBAgQyVbXFw8efJk2Co0CJlMVltbC1tFc5DBduXl5TQaSVoLhCAQCEaOHAlbRXOQwXZubm5HjhyBrUKDMDQ0pNPp1dXVsIU0CWrbISBAhtLuwYMHO3bsgK1CsxAIBJoc4p0Mtquvr6+rq4OtQrO4cOHCiRMnYKtoEi1uic+ePfvly5f4eqYKheL69esUCsXa2vratWuwpcHH2dk5MTERtoom0WLbTZw4MSMjo6amBgCA/T/9+/eHrUsj6Nu3b9++fWGraBItrmQDAwOdnZ0bPxLZ2dmFhIRAFaUpSCSS3Nxc2CqaRItth798NDQ0xD9jGNanTx9LS0vYojSC+vr6qVOnwlbRJNptuz59+iiHdtrZ2XXAWdlNweFweDyeVCqFLUQ12m07AMBXX31lYGAAAPj88881fw5BexIVFaWxL2+03na9e/d2cnKytLScMGECbC2aRWVlpcaWdmreUpTm1b9+VF2cXVcnkLWjqtahUCgUCgXek6KZmFozaDpYZ399t+567XbROXPmhIWF+fv7t9sVW05zhXBWUu3z2xVdA7ldA7m6nI9foRshkyrKC8RF72rL8uv7jDFpn4va2tpqX2n39jk/9ZVowGSLdpdEZmIfVoqFki+mmMMWAhnVFVN9rTzttRB5jnB8+hvrMKiZCaJ2uFZpaanGDkJRbbvCzDqMQtow03BhG+rkpbXHGMyLFy9q7HtC1bbjV0p59uQPvwoFrhWjQdweM7vs7e3xriUNRPUjRX2trEFzR81oOXLAL5e0w3WGDx/eDlf5ODS30wHxiZSWlmZnZ8NWoRpkO9Ly119/nT59GrYK1WjoyxPEp2NlZSUQCGCrUA2yHWnp1q1bt27dYKtQDapkSUtlZWVKSgpsFapBtiMtSUlJhw8fhq1CNch2pIXL5To7O8NWoRrUtiMt7u7u7u7usFWoBpV2pIXP56enp8NWoRpkO9KSmpq6e/du2CpUg2xHWvT09Ozt7WGrUA2yHWlxdXWNjIyErUI1GmG7K1cvBA3sDltFi9j83dqFi2fAVtEi6urq8vLyYKtQjUbYDtEWpKambty4EbYK1SDbkRYmk2lhoaHjw4nptwsZN3jkiJCpU8IAABUV5SHjBvcNHLBh/TY8NXjsoLEhk0LHT01LTzl+/EBqWrJUKvH16T5/XjiP9/6+YBj29m3C//Ztz8p+Z8I1/XranIEDhzZ/0ZKS4sNH9sa9eVVbK+LxLEOCJ44YPgZPevDw7qVLZ3Jys3R1Wf37DQqbMZ/JZOLRVU+dPvbgwZ2y8lJ9fYOAXoGzZy3W1dUFAHw5ZsDkSdNfxjyPjX155fLvHA7n7t2b5y+cLCoq4PEsQ8dPHTL4fXxMKpX65Omjo8f2FxcX2tjYrVi+wbWzJnaPubq6auzCf8SUdj4+3RIT4/DPb+Jfm5mZJ/z/Zl5eTmVlhZ9fj5KS4mXhszEKZc/uI7t3HeYLasKXz21oaMAPwzDswKHdUyaH7fvfj66uHlu3b8jMzGj+ojt2biqvKPtuy96ffrw4ZnTo3v9texnzHADw9Okfm7es8fPrcezo+RXLN0Q/ebB7zxb8lMu/nDt3/sT06fN+PBa1YvmGP/96fPyng3gSjUa7cfOKo4Pznt1HmEzm4+gHO3Z9M3jQiH3/+3H4sNE7dn7zx+P7+JGlJcU3bvyyImL997sOYxi2dZuGrtQtkUg0dhUoYmzn79vjbXICvgrHmzevgvoPrq0VFRTmAwDiE2INDAydnTr9euMyhmFr12xxdHR27ey+OvLboqKCx9EP8BykUunUyWG9e/d17ey+bOkaGo328NHd5i+amZXRzf8zN1cPK0vrUSNDDuz7ycnRBQBwLupE166+M8MWWFvZ9OwRMDNs4f37v5WWlgAABgQNOfLDmf79vrC2tu3m37Nf3y9iYp7juWEYxmQwZ89a5OHRhUajXbp8tndA39DxUzt3csOL6oryMvzIyqqKNas3e3l5e3l5jxkdmpubLRQKCbmNxJKUlBQREQFbhWqIqWR9fLqJRKLMzAxn505xb17Nnb0kJSUpISHWytL6Tfxrf78eGIYlJye6dvbQ47yfn2xuzrOwsMrISB04YAi+x8vLB//A4XAc7J1yc9WMjO31WZ/zUSeEQkGPHgFdvHzc3DwBAHK5PC0tedpXs5WHeXf1AwBkZqabmZkbGBje+/3Wru83l5eXSqXSurpaXV2W8kgPjy7Kzx9kMnvWIuVnG2s7A4P38X6MDI0BAHV1tRwO59NuIfHo6Oho7IrOxNjOzMzcxsYuITGOyzXJz8/19PROTkmMj48dPGhEfPzrr6bOAgCIRML0jNQvBv+zGp1EIqmoLFdustls5WcGkykWqwnQuXTJKkcH59/v3750+SybzR45ImT613MbGhpkMtmJk0dOnT7W+GD8QvsP7Pz9/u2li1d5eHZl0Bnno042LlPZ7PfWEYvFEomEyVQ9iYmp+89+DMPwsAStuVvthIeHx9atW2GrUA1hQwF8fbolJb0xMjJ2dHDmcDient779u8oKSkuKSn29emO/1O9vLzDl65pfFbjwkYsFuMNfwCAuK4OL0iak06jBQdPCA6eUFlZce/3Wz/+dMjQ0CgkeCKNRhszOnTY0C8bH2xoZCyTyW7/dn3K5DDlw4pIpLpyZDKZTCaztrY9ZrO2KTKZjErVxHAOhHWg+Pn1SEx68+bNqy5dfQEA7m5ehYX5fzz+3dbW3tycBwBwc/MsKMiztLS2tbXH/zAM43L/icygfAqpra3Nzcu2t29ucVihUPj7/d/wYAvGxtzQ8VPd3b0yMzMoFIqLi2tJSZHyKhYWVlQaTV9PXy6Xy2Qyff33c/hEItFfz6KbKqicnTvHx79Wbu4/uGv/wV0E3ap2Ii4ubtasWbBVqIYw23l7+5eVlf71LNrL0xuvMZ0cXa5eu+Dn1wM/YMTw4Lq62u07NqZnpObn5546ffzrGeNSUpLwVBqNdubsjwkJcQWF+Yd++F4ikQT1H9zM5TAM27d/+67dm9MzUguLCu4/uJOWluzt7QcACB0/NfrJw3PnT+Tl5aRnpH63dd2ixTNEIpGOjo6Lc+e7924WFOa/e5e+eu2SHj0CBAJ+bm72f2OFhARPfBnz/OcTh1NS3/5yJeratYturp5E3SsEYZWsHkevk4trSurbLv//ZODp5X316gU/n/dvvXg8i+93Hzl6dN+ixTOoVKq9vdPmb793d/cCAMhkUl1dVtj0+fv278jOyTQzNV+7ZoutbXOvsdls9vZtB44fP7AsfHZDQwOPZ/n1tDmDB40AAPT5vP/qVd+ejzrx84nDbDbH07Prnt1H8Ibj8oj1O3d9M33GOB7PcvrXc91cPZMS38ydP/X4sagP8g/sE7RkceTFS2fOR500N7dYtHDFgKDmfgYaiLe399GjR2GrUI3q0Dsv7lTWi4F3PzWtK8RHUJorjntYHrzYGrYQmKCXY6QlLi5uyZIlsFWoRqMHtY8Y1WSI+8gVmwICAttXjpahyessarTtzp290VSSbhOdagglXbt23blzJ2wVqtFo2ylfaSA+AhqNprERn1DbjrTExsauXbsWtgrVINuRltraWj6fD1uFajS6kkV8Cn5+fm5ubrBVqAbZjrTgb5Zhq1ANqmRJy9OnTzV2dWdkO9LC5/NRfDtEe9O3b99evXrBVqEaZDvSwmKxWCxWCw6EgOpKVodOoTNR/dsmUKgYx0inHS50+fLlY8eOteBACKj2FtuAWlFU3+5iOgTVpfVUWnssNVNTUyORtMdKBB+B6kqWa8lIj9P6Id2aSZ1QxrNvj36NqVOn4lM9NBDVpR3Xgq5vTIt7VNnuekhOeUF9zluBZy/9drgWhmFaZjsAwOejTRRyRczdCkl9e6xURHoUcpCXInp2o2TcMpv2ueLmzZtv377dPtdqLc09yfYZw339sOrXw7lAAVgczX3mlSsUQLOXMdbVo+WmCN0/M5i40rbdLiqXyw0NDdvtcq1CzerZAACFAgiqpLV8DV0QF++OT0lJCQsLgy2kSXQYFK4FHbYKDUJ9GYZhQN+Ypm+suaUdI6FOSitvn3a6FqGxk2TRyzEyM3r06IKCAtgqVEMG21GpVI0dagGRmpoajR1drLlVZ8uRy+V1dWoCpnRAHj58iCrZNoTJZBoZGcFWoXForOdIYju5XF5SUgJbhWaRkJCgyY/2ZLCdrq6uxjZiYFFaWqqxgYtJ0rbT0dHR2Ej4sAgKCgoKCoKtoknIUNpxOByRCA1c+BdCoVBjQwKQxHYGBgZ42GSEktWrV8fGxsJW0SRksJ2xsXF2tppAxx2N6upqBwcH2CqahAxtOzab3alTp8YxaBGnTp2CLaE5yFDa4U0Z9FShRC6Xi8Vi2CqagyS2s7Ozy8nJga1CU7h9+/a2bdtgq2gOktjOy8urshKNhX5Pdna2l5cXbBXNoX68nVYQHR199erVPXv2wBaCaBEkKe08PT0TExNhq9AU8vPzYUtQA0lsZ2xs7OnpqbHDy9qTV69effPNN7BVqIEktgMAWFlZRUdHw1YBn9LS0pCQENgq1ECSth0A4Pnz52fOnDlw4ABsIQj1kKe069mzp0gkUi5Q2zFpaGh4+vQpbBXqIY/tAABubm5Xr16FrQImFy9efPnyJWwV6iGV7UaNGnX9+nXYKmBSW1sbGhoKW4V6SGW7zp0729jYvH37FrYQaMyaNUuTR3cqIZXtAABffvnloUOHYKuAw9OnTxMSEmCraBFks91nn30mEAg6YNexTCZbtmyZhr8TU0I22wEAFi1apOHDftqCsrKyK1euwFbRUkhoOz8/PwqF8vvvv8MW0q7weDxra61ZLJQ83cWNEQgEX3755YMHD2ALaSfOnTvH5/PnzJkDW0hLIaftAABRUVF5eXnLly+HLaQ9GDFixI0bTa5GqYGQsJLFCQ0NzcjIiImJgS2kPdAuz5HZdgCAnTt3amyocqIQCAT37t2DraLVkNl2+vr6oaGhERERsIW0IXPnzrWxaaeotARC2radkt27d1tYWEycOBG2EOKprKxsaGjg8XiwhbQaMpd2OOHh4XFxccnJybCFEIxcLscwTBs91yFsBwDYsWPHzJkzNXwOX2sZNWqU9kb1I38li1NQULB3796dO3fCFkIMd+/etbOzc3V1hS3kI+kotkPDjzWKDlHJ4vTs2XPQoEHaPj4lLi5u4cKFsFV8Kh3IdnhvPoVCOX78OGwhH4lAIHj8+PH+/fthC/lUOlAlq+TQoUMODg5DhgyBLUQ9kyZNOnv2LGwVxNOxSjucefPmPXr0SDlQwMfHZ/z48bBFqeDUqVNpaWlffvklvjlx4kShUAhbFDF0RNvhXSp37tx59eqVv78/lUoVCAQaOBT+6dOncrk8Pz9/5MiRd+7cOXr0KIfDgS2KGDqo7QAAxcXFM2fOxD+XlZW9ePECtqJ/UVRUVFZWhq/MWVhYuG/fPtJ4ruPabsqUKcnJycpFGeVy+Z9//glb1L+Ii4trHMOqtLRUKxqjLaQj2m7s2LFv375t/CyFYVhFRYVGLW7xxx9/fBAHvLS0tF+/fvAUEUlHtN2lS5dCQ0MtLS0ZDIZyZ3Fx8evXr6Hq+gexWPzu3TvlJpVK5fF4/fv3f/ToEVRdhNERO1CUPH/+/OrVqwkJCRUVFQ0NDUOHDt2yZQtsUQAA8OzZszVr1tTU1HC5XBsbmyFDhgQGBpqamsLWRRhE2k4mUbx6WFWWX1/LlxGVZzsgl8tFIpFQKJDJ5JozCyY3N1dPj8Nmc+h0bVr/2NBMh86k2LqyHTxYzRxGmO3KC+ov7c3vGmhsaEZnsjV3kTVEm4IBrLxQzK9ooFBAv3FNFs/E2K44u/7PG+VfTLX69KwQ5ODV/QoqVfH5lyYqUwl4pJDLwB+XSoMmWH56VgjS4DeA21AP0mJVv1YhwHZ5abVMNpWqg316VggyYW6nmxErUJlEgO2qyyRm9rqfng+CZHAtGQ31qptwBCz+JBbJ5NJPzwZBNqhUrKKoXmVSR+wuRkAH2Q4BAWQ7BASQ7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAANkOAQFkOwQEkO0QECBgKACCrGRnZx49vv/t2wQAgJub58wZCxwdnQnJGZV2/7Bx08o7d7Us5HnbUV5etnjpTIGAH7li44qI9ZUV5SsiFxAVDQOVdv+Qlpbcs2dv2Co0hbv3borFdd9t2avH0QMAWFhYTQ8bn5gYR8gtglPalZeXrVqzZPDQgJBxg6MunPrxp0Nfff1+eXupVHri5JGp04IHDek1eero679exvfn5GT1C/KPjYtZuz581Oig0cED9+3fIZO9n6JWXV313bb14ycMGzw0YN6CabFx75ejuHrt4ujggX/++Xh08MAfDu8FAFRVVX63bX3IuMF4/leuROFH9gvyLyou3L5j04hRffE9Dx7enTN3ypBhvceEfHHg4O6WxKBtKnMAwOjggVeuRP1weO/Y8UOGjwxctWZJRUU5nnTr9rWvZ4wbPDRg1Oig9RuWl5aW5OZm9wvyj4+PVSrpF+SvvBV4anJKEgAgLT1lxcoFo0YHDRvRZ936iOLiIvyYjZtWbvom8ucTh4cM6/3s2ZOmBL+Med4vyB+vRnHeJif2C/J/GfN8xIjg40fP454DAJiZ8QAAAqHq0cKtBY7tdn2/OT095dtvdm/fuv9N/OuHj+4p40IcPvK/CxdPT5rw9Y/HL4wNmXTg4K5bt68BAKg0GgDg4KHdE8Z/df3qg7Vrtly9djH6yUN8xuHKyIVJSfErV2w88sMZ187ukasWZWZmAAB0dHTE4rorV6NWrtg4atRYAMCOXd+8TYpft+a740fPT5ww7eAP3z/98w8AwMWo2wCAhQuWnzl9HQDw9Okfm7es8fPrcezo+RXLN0Q/ebB7j/optE1lDgCg0WjnL5y0t3c8f/bGT8cvpqennD5zHAAQHx+7a/fm4DETfjx+Yet3/6vhV2/6NtLW1t7MzDwx6Q1+bnz8azMz84SE9y58E/9aj6PXuZNbSUnxsvDZGIWyZ/eR3bsO8wU14cvn4svW6+joZGZlpKWnbPtun7t7k8su+vp0MzQ0evL0n1nf0dEPDA2NfH266evp29jYKff//eJPDMOayapVQLBdZWXFixd/TZ40o5t/Tycnl7Wrt/BrqvEkoVB4/ddL48dNGTRouLWVzaiRIYO+GH7u/AnluYF9Bnh4dAEA+Pl2t7SwSk19CwCIefV3WnpKRPhaX59udnYOC+ZHmJtbXLkahUeZEIvFIcETe/YIsLSwAgDMnxe+Y8fBrl19bWzshg4Z5ezUKSbmOQBAX98AAMBisQz0DQAA56JOdO3qOzNsgbWVTc8eATPDFt6//1tpqZpoFU1ljmNn6zBk8EgajWZmZt69Wy9cfFb2OwaDMXjQCCtLa3c3zw3rts2fFw4A8PHulpAYh58Y9+bVsKGj4xvZzte3O4VC+fXGZQzD1q7Z4ujo7NrZfXXkt0VFBY+jHwAAFAAUFuZHrtzUtauvgYFhU4KpVGpgn6DGtnvy5GG/vgOp1H9NOS0uLtq3f8fwYaOtLImZRwzBdgUFeQqFwtOjK77JZrP9/Hrgn9+9S5NKpf5+PZUHd+3qV1iYX1tbi286ObookzgcPaFQAABITk7U0dHx7uqH76dQKF28fDIyUpVHNv6N6jJ1f7lyfsbM0JBxg8eEfJGZlcHn13ygUC6Xp6UlN5aBZ56Zmd78V2s+c8dG4vX09PkCPgDAx9sfw7BFS8Ju3rpaVFxobMx1d/PEf1dJiW8UCkVVVWVBQd6okSE1NdVFxYUAgMTEOPyOJScnunb2UNaD5uY8Cwsr5Re3sbHDf0LN0zdwYEFBXlbWO7zKLiwqCOo/uPEBeXk5i5eGuTh3XjCfsIVlIDxS1NRUAwB0Wf/MGtf//7tTWysCACwNn40H2AIA4NN4K6sq8E16o6glytTaWpFEIhk0pJdyv0wmMzbmKjfZ7PchuqRS6YrIBTKZbMH8CFsbeyqVunZ9+H8VisVimUx24uSRU6f/tXZURWV5M99LbeaMf4vHv6Gtrf2BfT+fv3Dy6LH9gu+3uLl5Lpgf4e7m6evbXSAUZGdn5uRmOTm6GBgYdu7snhAfCwAoKSnGbScSCdMzUr8Y/JkyT4lEohSp/NbN06WLD5dr8uTpIwcHp+joBzxzC7w+wUlNS14ZudDL03vd2u8IjE8AwXa4deobtdAFAj7+Ab9Ta1ZvdnT4V/+Qmal5aVmTFRweseHYkXONdyobi41JTk7MzMz4355jXbr44HtqqqsseB/O8GUymTQabczo0GFDv2y839DIuJnv1cLM/4uTk8va1ZtlMllCQtyPPx9avWbJxajbXK6JnZ1DYtKbd+/SvLx8AABent4JiXEKhcLK0hpvMLDZHC8v7/ClaxrnpqvbXBSI/0KhUAIDBzx9+mjqlLDoJw/79x+kTMrNzV6+Yn7vgL7hy9Z8UO1+IhAqWSsrGwBASmoSvikSiV69+hv/7OjooqOjU1VVaWtrj//p6xsYGBg2/ztzdfVoaGiQyWTKs+h0homJ2X+PrG+ob1y4JiXFFxUXNo6LgH+mUCguLq4lJUXKDC0srKg0mr6efjMy1GaukuTkxKSkeLyZ5e3tN/3ruTU11ZWVFQAAP78eiUlv3sS/7trVF7ddfEJswv/XsHgXbkFBnqWltVInhmFcruqJ+M3QL3Bgekbqq9cv8vJylDWsVCpduz7cz7f78oh1xHoOku0srTu5uJ49+1NSUnxubvbW7euN/r9C5HA4w4ePOXHyyMNH9wqLCmLjYiJWzNu2Y2PzGfr5dndx7vzd1nVxca+KigvvP7gza/bE679e+u+Rzk6d6HT6latRFRXlL2Oe79u/o5t/z7z8nKqqSgaDwWAw3sS/Ts9IlUqloeOnRj95eO78iby8nPSM1O+2rlu0eMYHAedannkzZ/394q8165Y9jn5QUJifnpF65UoUz9zC3JwHAPD17hYb+zInJ8vL0xsA4OHZNT8/N+bVc6XtRgwPrqur3b5jY3pGan5+7qnTx7+eMS4lJUn9/+DfeHh0MTfn/XB4j6Ojs/I9xPVfLxcW5vfvPyjuzavYuBj8Lz8/t7WZqwROd/HaNVt27v52afhsE67ppEnTucYmyps1b85SPY7e0WP7KirKjY25vT7rM2P6/OZzo1Kp27ft/+HI3g2bVojFdTye5ZQpYWNDJv33SENDoxXLNxw/fuDe77c6dXJbuWJjWXnpt5tXLYuY8/OPFyeETou6cPLZsydnTl/r83n/1au+PR914ucTh9lsjqdn1z27j7DZ7GZkNJ95U2dNnjRdKpUcPry3vKIMv9C2rfvwpm3Xrn6VlRU2NnaGhkYAAD2Onr29Y1bWO29vf/xcHs/i+91Hjh7dt2jxDCqVam/vtPnb7z+ijwPDsMA+Ay5eOjMzbIFyZ2zcS5lMtn7Dv9aBHjUyZMniyNbmr+KKnx565+/fKiUS0DWwuXbPB4jFYolUonwEWxY+R1/fYOOG7Z+oBKFR1AllN47kzvjG4b9JcEq71WuWVFZVhC9dY2Rk/Oz5k9i4mK1b9kJRgoACtEr20A/fr9sQUV8vtrS0jlyxUVtehipfnf2XyBWbAgIC21dOizh3/sT5qBMqk2xtHQ7u/7ndFUGqZLUX5YvU/6Knp6+ZkTdra2vr6mpVJtFotGbeYXwiGlfJai8f0T0BHRaLxWK1rjOvrUHj7RAQQLZDQADZDgEBZDsEBJDtEBBAtkNAANkOAQFkOwQECLAdRgFUKlqUAvEhGAUwdFUP1CPAdiw9qqBa8un5IEiGqFqqQ1ddHhFgO64Fo16kTUsqItoHfqXEwkH1OjkE2M7CgQkwkJvc3MhbRAfkxW9l/gONVCYRtrDnlQOFzt56Dl56hOSG0Gok9fJ7pwoGTDQ3sVQ9JIfIZYzvniouK2jQ5+owWWhgSweFyabkp9cyWZTPhnEtHJhNHUbwou2CSml5Yb2wpuOuQXbixIlBgwZZWFjAFgIHOpNibE43tWY0fxjBxZKeMU3PuEMXdaWHY6zdB7q7q5+O35FB3cUICCDbISCAbEcwurpoRWf1INsRDJvNVsYNQjQFsh3BlJeXE9s5QEqQ7QhG0+ZoaSbIdgSjjACJaAZkOwQEkO0IxtLSEj1SqAXZjmAKC9WHUkQg2xGMkZERKu3UgmxHMFVVVai0UwuyHQICyHYEY2dnR3iAafKBbEcwOTk5ypXQEE2BbIeAALIdwdjb26tciQXRGHSDCCY7O1sul8NWoekg2yEggGxHMLa2tqi7WC3IdgSTm5uLuovVgmyHgACyHcHweDxUyaoF2Y5giouLUSWrFmQ7BASQ7QgGzaVoCch2BIPmUrQEZDuCMTExQY8UakG2Ixg0T7YlINshIIBsRzBoBEpLQDeIYNAIlJaAbEcw+vr6sCVoAch2BMPn82FL0AKQ7RAQQLYjGDQ9uyUg2xEMmp7dEpDtCIbL5aLSTi3IdgQjEolQaacWZDuCEYvFsCVoAQSvwtNh8fX1xTAMwzC5XI5XshiGOTo6Xrx4EbY0TQSVdsTg4uKCu41CoeD+Y7FYc+bMga1LQ0G2I4bx48czGP9aaMvBwaF///7wFGk0yHbEMMKtwrgAAAbDSURBVGbMmMbL27HZ7K+++gqqIo0G2Y4wJk6cqCzw7O3tUVHXDMh2hDFmzBhzc3N8OsXUqVNhy9FokO2IZPz48RQKxdHRMSgoCLYWjabjdqAUZNQJKqUigbRBLK+vJWyE3O3bt729vS0tLQnJTZdDwTCMpUdlG+jw7Bm6HJLECe1wtst4I0p7LchOEvEc9Rrq5VQdKoVOA0BDX2dRqZi0XiKTyDCgqCquNeDSXbzZngEGDF3trqY6kO0y40XR18r1TVlUJkPPlEWhaqjVmqG2ul5UIaopFrl20+s9igtbzsfTUWx341gxv1pu6mhMZ+nA1kIAFdnVRWlVg6ZauPiwYWv5GMhvu/LChqiduc49rZj6dNhaCKYoqdTejf7ZMO0r9khuO0GV9PK+Aofu1rCFtBWV2VWWDtSeg41gC2kdZLZdaV79rZ9KHLpbwRbStpS/qzLkygdMMIMtpBVo9wNRM8hlikt780jvOQCAiZNRVTl486QatpBWQFrb3fyxxOUzG9gq2glTZ25GfH1xttYM9SOn7ZKe84UCQGfTYAtpP3SN9f64XA5bRUshp+3+/LXCzNkYtop2hWXIkMopWYki2EJaBAltl/hXjYmdPo2uoe+R3iQ+iFjXQyQivilm6sBN+EtAeLZtAQltl/xCwOAwYauAAINDK82rr6mQwBaiHrLZTtqgKMuvZxt3RNsBAPRMdLMStKCeJVujOye51syhDYPfxMbfe/znuZKyLAaD5eP1xZABc+l0JgDgVNRqDAOdXT57FH2qRlBmZmI3eniEnY0XAEAmk16/ved1/B2FXO7eubezo3/bydMz4xRlC7zb7gIEQbbSrrK0XiZrq3f8iW8fn720rpNz9/D5Z8aPXhef9PDyr1vxJCqVlpXzJjcvacm8UxtX3mGxDC5c2YwnPYw++XfMtZFDliydd8rB3vv+45/aSB4AQIdJLcysa7v8iYJsthNWy2iMtnqYePjklKO979CB80y4Nm6deg37Yv7rN3eqa0rw1IaGupFDljDounQ607fL4NLy7IYGMQDg1ZvfPN0Du/uOMOHa9Ooe3MmpRxvJAwDQGDSxUNp2+RMFsl1Lkcvl+YXJnZy7K/c42vsCAIqKM/BNE64NXuECAFi6+gCA2jq+VCopr8izsXJXnmVr7dEW8nAwDNDoFLFI0+M6kq1t13bhRyQSsVwuu/fw2O+Pfmy8ny9430lLozH+c5KioaEOAKDTKInBQAtXkM52HENqRYWsLXLW0WFSqbTePcf38Bv5ryuym+uX1qEzAQB19ULlnrq6NuxaUyiAVCJnsjW9EiOb7fQMaSWFbdK4oVAoVhauVdVFZqb2+B6pVFJdU8JiNffgrEOjGxlaFBWnK/ekvXvRFvLeSxJLdbXhlaCm/yxai5EZnUZrq6FcfXtPTnj76GH0ydKynILC1HOXNxw8PkssVtNP5uP1ReLbx89jrhUVZzz+82xhUVobyQMASOplFk66bZc/UWjBL6NV2Lqx7pwq5jq0yYDbLh79JgRvevTk1N0HR5lMjr1tl7nTDzGZaoaVD+wfJqqtvnlnn1whd+sUMOyLBacurJIr2qTVLygTdu763yamxkHCYZ6/7CtgGBtwuFrwoyecd3/ljV1irc/V9NKEbJUsAMCtu16DsB62CgjUiySmNkzN9xwJK1kAgHtP/T9vZOnz9JrqwEtMfhx15RuVSWxdA1Fdjcqknn5fDh+8kCiRWTlxP54JV5kkl8soGEVlV1Cv7iFDB85tKs/yzIqA4doxqYKElSwAIPkF/82ftTxXU5Wp9Q11IlGVyqSGBrGyy/cDGAw2m2VAlEKJpF4grGgqiUrVUbmCVDMaRFViUXHVuGXaMVmJnLYDANw8Xkw3MiTHrNiWUJlV3nuEoZmNFjxPkLNthzNsBi/taT5sFe1EWUa5S1emtniOzLbDMDA+3Cbrb/I7r/RdJdcM8wogrAHQDpC2ksURVksv7S1w6G6tqbF1PpWK7CpbJ1q3LwxhC2kdpC3tcDiGtFFzLBLvZ4kFDbC1EIxCAYqSSqwdKFrnOfKXdkp+O1FSVS7j2hsz2GR4yKjIqS5Orxo23cLeA4Xe0WyykkRPrpazjXWpTIa+KZtC0756V1QlFlXU8ouFHr30tTHijpIOZDuczHhRWqwwO0loastpaFDQ6FSqjo7GtjUolPdhFYFCUVVUa2xOd/HhePQyoDO07zfTmA5nOyWF78SCKomIL62vIzKILLGw9CgAYGwDGtuAamGvy2Bp6u+jlXRc2yEgQpJfD0K7QLZDQADZDgEBZDsEBJDtEBBAtkNA4P8AN72u7tkVGk0AAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display, Markdown\n",
    "display(Image(agentic_rag_compiled.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eba8c184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini is Google's most capable AI model yet, designed to accelerate the development of large-scale generative AI models and help developers and enterprise customers train them faster. Gemini provides direct access to Google AI, offering assistance with writing, planning, learning, and more. It is equipped with comprehensive safety evaluations, including for bias and toxicity, making it one of the most advanced AI models from Google to date. Additionally, Bard Advanced, a cutting-edge AI experience, will be launched soon, providing access to the best models and capabilities starting with Gemini Ultra.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is gemini?\"\n",
    "#response = agentic_rag_compiled.invoke({\"question\": query})\n",
    "\n",
    "# First invocation\n",
    "query1 = \"What is gemini?\"\n",
    "state1 = agentic_rag_compiled.invoke({\n",
    "    \"question\": query1,\n",
    "    \"documents\": [],\n",
    "    \"web_search_needed\": \"No\",\n",
    "    \"history\": []  # Initial empty history\n",
    "})\n",
    "print(state1['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1cc1ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the competitors to Gemini in the AI model space include OpenAI's GPT-3, Microsoft's Turing-NLG, and Facebook's RoBERTa. These models are also large-scale generative AI models that offer advanced capabilities for various tasks such as natural language processing, text generation, and more. Each of these competitors has its strengths and weaknesses, and developers and enterprise customers may choose one over the other based on their specific requirements and use cases. Conducting a thorough competitive analysis can help in understanding how Gemini stacks up against its competitors in terms of features, performance, safety evaluations, and overall capabilities.\n"
     ]
    }
   ],
   "source": [
    "# Create a new state, but keep the history from state1\n",
    "query2='Who-are-its-competitors'\n",
    "state2 = {\n",
    "    \"question\": query2,\n",
    "    \"documents\": [],  # Reset documents\n",
    "    \"web_search_needed\": \"No\",  # Reset web_search_needed\n",
    "    \"history\": state1[\"history\"]  # Keep the history\n",
    "}\n",
    "state2 = agentic_rag_compiled.invoke(state2)\n",
    "print(state2['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new state, but keep the history from state1\n",
    "query2='Who-are-its-competitors'\n",
    "state2 = {\n",
    "    \"question\": query2,\n",
    "    \"documents\": [],  # Reset documents\n",
    "    \"web_search_needed\": \"No\",  # Reset web_search_needed\n",
    "    \"history\": state1[\"history\"]  # Keep the history\n",
    "}\n",
    "state2 = agentic_rag_compiled.invoke(state2)\n",
    "print(state2['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05f06cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini is Google's most capable AI model yet, designed to accelerate the development of large-scale generative AI models. It allows developers and enterprise customers to train models faster, bringing new products and capabilities to customers sooner. Gemini has comprehensive safety evaluations, including for bias and toxicity, making it one of the safest AI models from Google to date. Users have direct access to Google AI for assistance with writing, planning, learning, and more. Gemini is part of Google's efforts to provide cutting-edge AI experiences to users through platforms like Bard Advanced.\n"
     ]
    }
   ],
   "source": [
    "state2 = agentic_rag_compiled.invoke(state1)\n",
    "query2 = \"Summarize the key points.giveonewo\"\n",
    "print(state2['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a1b2703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is gemini?',\n",
       " 'generation': \"Gemini is Google's most capable AI model yet, designed to accelerate the development of large-scale generative AI models and help developers and enterprise customers train them faster. Gemini provides direct access to Google AI for tasks such as writing, planning, and learning. It is equipped with comprehensive safety evaluations, including for bias and toxicity, making it one of the most advanced AI models from Google to date. Additionally, Gemini will be launching Bard Advanced, a cutting-edge AI experience that offers access to the best models and capabilities, starting with Gemini Ultra.\",\n",
       " 'web_search_needed': 'Yes',\n",
       " 'documents': [Document(metadata={}, page_content='Introducing Gemini: Google’s most capable AI model yet This next generation TPU will accelerate Gemini’s development and help developers and enterprise customers train large-scale generative AI models faster, allowing new products and capabilities to reach customers sooner. Building upon Google’s AI Principles and the robust safety policies across our products, we’re adding new protections to account for Gemini’s multimodal capabilities. Gemini has the most comprehensive safety evaluations of any Google AI model to date, including for bias and toxicity. Early next year, we’ll also launch Bard Advanced, a new, cutting-edge AI experience that gives you access to our best models and capabilities, starting with Gemini Ultra.\\n\\nGemini gives you direct access to Google AI. Get help with writing, planning, learning, and more. How Gemini works. The simple answer.\\n\\nBard is now Gemini. Get help with writing, planning, learning, and more from Google AI.')]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea31ce5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask a question about your documents or (STOP) to stop the conversation: What-is-claude\n",
      "\n",
      "Claude AI is a generative artificial intelligence chatbot and a family of large language models developed by the research firm Anthropic. Claude adheres to Anthropic's Constitutional AI philosophy, which is a code of ethical norms that differentiates Claude from other AI models like ChatGPT and Google's Gemini. Anthropic offers free access to their best Claude model through their chat interface at claude.ai, which is still in open beta testing as of October 2023. The free tier of Claude AI provides users with access to Anthropic's latest and most capable model, Claude 2. Developers can access Claude AI models through the Anthropic API or Amazon Bedrock. Claude is known for its 100K token input limit, transparent approach to AI safety with a \"constitution,\" and the free access to the best Claude model developed so far, Claude-2.\n",
      "Ask a question about your documents or (STOP) to stop the conversation: How does it compare with Gemini\n",
      "\n",
      "In comparison with Gemini, Claude AI offers a unique approach to AI ethics and safety through Anthropic's Constitutional AI philosophy. While Gemini and ChatGPT focus on providing AI chatbot services, Claude stands out for its transparent approach to AI safety with a \"constitution\" that sets ethical norms for its operation. Additionally, Claude offers free access to its best model, Claude-2, through the claude.ai platform, which is still in open beta testing as of October 2023. This contrasts with Gemini's paid versions, such as Gemini Advanced, which may offer additional features but come at a cost. Overall, Claude AI distinguishes itself through its ethical framework, transparent safety measures, and free access to its latest and most capable model, making it a compelling choice for users seeking an AI chatbot with a focus on ethics and safety.\n",
      "Ask a question about your documents or (STOP) to stop the conversation: is it better than chat gpt, evaluate pros and cons\n",
      "\n",
      "Claude AI and ChatGPT both have their own set of pros and cons, making it important to evaluate them based on specific needs and preferences.\n",
      "\n",
      "Pros of Claude AI:\n",
      "1. Ethical Framework: Claude AI follows Anthropic's Constitutional AI philosophy, setting ethical norms for its operation, which can provide users with a sense of transparency and trust.\n",
      "2. Transparent AI Safety Measures: Claude's approach to AI safety includes a \"constitution\" that ensures a transparent and accountable operation, addressing concerns related to AI ethics.\n",
      "3. Free Access to Best Model: Claude offers free access to its latest and most capable model, Claude-2, through the claude.ai platform, which can be a cost-effective option for users.\n",
      "\n",
      "Cons of Claude AI:\n",
      "1. Limited Input Tokens: Claude AI has a 100K token input limit, which may restrict the length and complexity of generated content compared to other models.\n",
      "2. Open Beta Testing: As of October 2023, Claude AI is still in open beta testing, which could mean potential bugs or limitations in its functionality.\n",
      "\n",
      "Pros of ChatGPT:\n",
      "1. Speed and Accuracy: ChatGPT allows for quick and accurate text generation, which can be beneficial for tasks that require rapid completion.\n",
      "2. Wide Usage and Recognition: ChatGPT is well-known and widely used, which may provide a sense of reliability and familiarity to users.\n",
      "\n",
      "Cons of ChatGPT:\n",
      "1. Limited Complexity: ChatGPT may struggle with more complex ideas or topics, limiting its ability to generate content on certain subjects.\n",
      "2. Paid Versions: While ChatGPT offers free versions, advanced features may require payment, which could be a drawback for users looking for cost-effective solutions.\n",
      "\n",
      "In conclusion, Claude AI excels in its ethical framework, transparent safety measures, and free access to its best model, making it a strong choice for users prioritizing ethics and safety. On the other hand, ChatGPT's speed and recognition can be advantageous, but its limitations in handling complexity and potential costs for advanced features should be considered. Ultimately, the choice between Claude AI and ChatGPT depends on individual preferences and requirements for AI chatbot services.\n",
      "Ask a question about your documents or (STOP) to stop the conversation: stop\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "state1 = None\n",
    "\n",
    "while True:\n",
    "    query = input(\"\\033[94mAsk a question about your documents or (STOP) to stop the conversation:\\033[0m \")  # Blue prompt\n",
    "    if query.upper() == 'STOP':\n",
    "        break\n",
    "\n",
    "    if count == 0:\n",
    "        state1 = agentic_rag_compiled.invoke({\n",
    "            \"question\": query,\n",
    "            \"documents\": [],\n",
    "            \"web_search_needed\": \"No\",\n",
    "            \"history\": []\n",
    "        })\n",
    "    else:\n",
    "        temp_state = {\n",
    "            \"question\": query,\n",
    "            \"documents\": [],\n",
    "            \"web_search_needed\": \"No\",\n",
    "            \"history\": state1[\"history\"]\n",
    "        }\n",
    "        state1 = agentic_rag_compiled.invoke(temp_state)\n",
    "        \n",
    "\n",
    "    print(\"\\n\" + state1['generation'])  # Black response with newline\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e65177ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gemini is Google's most capable AI model yet, designed to accelerate the development of large-scale generative AI models and help developers and enterprise customers train them faster. Gemini provides direct access to Google AI for tasks such as writing, planning, and learning. It is equipped with comprehensive safety evaluations, including for bias and toxicity, making it one of the most advanced AI models from Google to date. Additionally, Gemini will be launching Bard Advanced, a cutting-edge AI experience that offers access to the best models and capabilities, starting with Gemini Ultra.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90854d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who-created-it?\"\n",
    "response = agentic_rag_compiled.invoke({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebd0609a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'who-created-it?',\n",
       " 'generation': 'The study series for beginning readers ages 4-7 was created by the director, screenwriters, and other individuals involved in the production of the series. The specific creator or creators are not mentioned in the provided context.',\n",
       " 'web_search_needed': 'Yes',\n",
       " 'documents': [Document(metadata={}, page_content='An all-new study series for beginning readers ages 4-7. Each book is designed to help children build a familiarity with and love for God\\'s Word at an early age.\\n\\nMaria Sciullo of The Pittsburgh Post-Gazette wrote: \"Dylan Grazer and Lillis are standouts among a pretty good bunch of child actors.\"[450] Tasha Robinson of The Verge praised all seven of the central children, saying each are \"well-cast and give strong performances\" in the film.[451] She also said Ray Taylor\\'s portrayal of Ben Hanscom is \"surprisingly tender and nuanced\", Skarsgård seemed \"like a real threat\" as Pennywise, and that Lillis is close to \"heartbreaking\" as Beverly Marsh.[451] Christy Lemire of RogerEbert.com wrote that \"Despite the many terrifying moments they endure in their quest scenes that will leave you trembling and giggling at once It is even more powerful in the warm, easy camaraderie between its young stars.\"[452] Lemire praised the \"well-chosen\" cast, saying the \"that combination of tones\" from the performances make the film work.[452] She spoke of Skarsgård as \"working well,\" as he doesn\\'t appear to be laboring so hard to frighten, and that Lillis displays a \"star-making\" performance\".[452] Marc Savlov of The Austin Chronicle heralded the film, its director, and screenwriters, by stating: \"Muschietti and screenwriters Palmer, Fukunaga, and Dauberman have managed the translation to the big screen nearly as well as Rob Reiner did with Stand by Me (1986).[453] Entertainment Weekly journalist Chris Nashawaty summarized \"It is essentially two movies.')]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c12c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e87e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
